\section{Related Work}

Some works CITE
Leino et al. [2021]; Zhang et al. [2022a] Sun et al. [2022]  Chen et al. [2021], REGLO focus on training a network to be - rather than proving that the DNN is as we do - gobally robust .
Other work estimate global robustness bounds, but without hard verification certificates CITE Bastani et al. [2016]; Ruan et al. [2019], Gopinath et al. [2018], e.g. using probabilistic guarantees  Levy et al. [2023]; Mangal et al. [2019].

Closer to our paper, several works consider a kind of global Lipschitz bound, to understand how the output change with input perturbations, as \cite{Marabou} and \cite{ITNE,GROCET}. However, they do not consider whether the classification changes. 

The most related work is Vhagar \cite{vhagar}, which also computes $\beta^\varepsilon_{i,j}$ bounds, but limited to $L_\infty$ perturbations (and variants). They do not however report actual 
real-time certified robust percentage, as we do in Table \ref{table.cert}. Last, their hyper-adversarial attack to find better lower bounds seems extremely efficient, and we will consider it in the future.

Technically, none of the MILP base work \cite{vhagar,ITNE,GROCET} 
consider $L_1$ bounds. Further, they use the classical MILP encoding from \cite{MILP}, and not our novel "2v" model, nor even our "1v" model. However, \cite{ITNE,GROCET} 
defines the {\em diff variables} $y,\hat{y}$, adding explicitely the linear relaxation $\frac{y_i-\gamma_i}{2} \leq \hat{y}_i \leq \frac{y_i+\gamma_i}{2}$ implied by our modelS, Eq. (3) from \cite{ITNE} corresponding essentially to it. \cite{vhagar} does things differently, adding per neuron constraints (depending on the perturbation) between the (binary) variables to simplify the MILP problem. 

