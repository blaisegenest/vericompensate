While deep neural networks (DNNs) have demonstrated remarkable capabilities, achieving human-like or even superior performance across a wide range of tasks, their robustness is often compromised by their susceptibility to input perturbations \cite{szegedy}. This vulnerability has catalyzed the formal verification community to develop various methodologies, each presenting a unique trade-off between completeness and computational efficiency~\cite{Marabou,Reluplex,deeppoly}. 
This surge in innovation has also led to the inception of competitions such as VNNComp~\cite{VNNcomp}, which aims to systematically evaluate the performance of neural network verification tools. Notable examples include NNenum~\cite{nnenum}, Marabou~\cite{Marabou,Marabou2}, and PyRAT~\cite{pyrat}, as well as frameworks such as MnBAB~\cite{ferrari2022complete} (which builds upon ERAN~\cite{deeppoly} and PRIMA~\cite{prima}) and $\alpha,\beta$-CROWN~\cite{crown,xu2020fast}, based on branch-and-bound methodology \cite{cutting,BaB}.

These tools focus on {\em local} robustness: given a DNN, an image and a small neighborhood around this image, they verify whether all images in the neighborhood are assigned in the same classification. This neighborhood is provided by a maximal perturbation of the input image, often an $L_\infty$-norm constraint. Under this metric every subpixel\todo{what is a subpixel here? pixel component like each R/G/B?} of the input image can vary in a very small range, typically $\frac{2}{255}$ (that is 2 levels of grey/blue/red/green). 
+Although it is not necessarily the most semantically meaningful perturbation,
+$L_\infty$ is the usual choice because it is easier to verify since it is perfectly linear and specifies subpixel perturbations independently.

Crucially, however, these verification tools for local robustness are too computationally-intensive for real-time decision-making pipelines. For instance, consider an autonomous vehicule processing a live video feed: images of the feed cannot be certified robust in few ms on embedded hardware. \eca{This prevents the development of safety filters that could skip non-robust images and only consider certified robust images.}

\smallskip

In this paper, we consider {\em global} robustness, that is we do not restrict the certification process to the neighborhood of a specific, fixed input. We follow a two-step procedure. 
The first step, performed offline, computes global bounds on the \eca{maximum possible} shift between output values of different decision classes due to a perturbation, following an approach similar to VHAGaR~\cite{vhagar}. 
%
Specifically, for any two decision classes $C$ and $D$ and a perturbation $\varepsilon$, we compute upper and lower bounds 
$$\beta^{\text{perturb}}_{C,D} = \max_{|I-I'| \leq \text{perturb}}(x_C - x_D +x'_D - x'_C)$$
where $x_C,x_D$ is the value associated with output neurons $C,D$ from any input image $I$, and $x'_C,x'_D$ from its perturbed image $I'$. 
Unlike local robustness methods, which require $k$ separate calls, computationally expensive calls to certify $k$ images, the global bound $\bar{\beta}^\varepsilon_{C,D}$ is compute offline once per network and remains valid across the entire input space. 


\todo{shouldn't we unify notation w/ the section 4?}
The second step is real-time, being performed with the DNN inference of the image $I$ considered: it suffices to consider the class $C$ with the highest output value $value_{I}(C)$, and check whether for every other class $D \neq C$, 
$value_{I}(C) - value_{I}(D) > \bar{\beta}^\varepsilon_{C,D}$. 
If this is the case, then we are certified that image $I$ is robust for perturbation $\varepsilon$, because $\varepsilon$-perturbed image $I'$ could at most get  $value_{I'}(D) \leq \bar{\beta}^\varepsilon_{C,D}  - (value_{I}(C) - value_{I}(D))  + value_{I'}(C) < value_{I'}(C)$, hence $C$ is also the predicted class for image $I'$. This check typically requires only a few dozen CPU instructions, which can be completed under 1 ms on a single CPU core. When an image fails this certification, one could either skip it (e.g., in a video stream) or revert to a safer, degraded mode until a trustworthy, robust image is received.


Our main contributions address the challenges to compute the {\em global bounds} $\bar{\beta}^\varepsilon_{C,D}$, for $C,D$ output neurons:
% for standard ReLU DNNs (e.g. \cite{vhagar}). Our findings can be extended to other activation functions, following similar extention by \cite{DivideAndSlide}:
%, with updated MILP models e.g. for maxpool:
\begin{enumerate}
	%\item  Our first contribution studies the {\em LP relaxation} of the exact MILP encoding of ReLUs. {\color{blue} We establish in Proposition \ref{LP} its equivalence with the so-called "triangular abstraction"}.
	
	\item We develop a novel {\em Diff MILP encoding} for the global robustness problem, %called the {\em "2v" model}, 
	where the variables are the values of the perturbed neurons, as well as the difference between the original and the perturbed neuron values (called the {\em diff variables}, introduced in \cite{diff}). We study and encode how the {\em diff variables} evolve after passing through a ReLU (Prop.~\ref{Prop2}), see Section \ref{s.diff}. 
	Compared with the {\em classical MILP model} \cite{MILP} employed in 
	\cite{vhagar,lipshitz,ITNE}, which considers the input and the perturbation but {\em diff variable}, we keep the same number of 2 binary variables per ReLU.
	%the results are more accurate for the same runtime.
	%the linear relaxation is much more accurate, as each {\em diff variable} can be bounded after a ReLU as a function of the value of the {\em diff variables} before the ReLU, whereas the linear relaxations of the classical model is extremely inaccurate, as the variables are independent of each other. This was observed in \cite{lipshitz,ITNE}, and constraints encoding
	%a part of the linear relaxation of our "2v" model were added explicitly. 
	%Experimentally, 
	However, our {\em Diff MILP model} is more efficient, one reason being 
	the accuracy of its linear relaxation.
	%The number of variables a priori doubles compared with local robustness, from each neuron value in the perturbed image to each neuron value in the perturbed image {\em and} in the original image, as the original image is no more fixed. 
	%Recall that the worst case complexity of MILP is exponential in the number of binary variables \cite{DivideAndSlide}. 
	%A straightforward MILP model would be to use the  for each of these variables, as in \cite{vhagar,lipshitz}. The main issue with the classical model is that its linear relaxations is extremely inaccurate, as the variables are independent of each other. Instead, we develop another exact MILP model, 

	\item Further, from the {\em Diff MILP model}, which is exact, 
	we develop two abstract MILP models, which are more efficient but also asymptotically less accurate than {\em Diff}. 
	Namely, the "2b+1" model, accurate on the {\em diff variables} but abstract on the perturbed variables; while the "1b" model has a unique binary variable per ReLU, only considering the {\em diff variables}.
	%\item We adapt the Solution Aware Scoring from \cite{ATVA25} to our novel MILP models, in order to select the most important ReLUs to be treated using complex binary variables, while less important variables are treated using linear relaxation. The chosen number of binary variables depends upon the complexity of the DNN as well as the targeted runtime.

   \item  In terms of perturbations, we consider conjunctions of $L_\infty$- and $L_1$-norms, which allow to accurately describe perturbations. For instance, "each subpixel is perturbed by at most $\frac{50}{255}$ ($L_\infty$) and the sum of the absolute value of perturbations over all subpixels is at most $1$" ($L_1$-perturbation). While $L_1$-perturbations are not linear (because of the absolute values), reason for which it is seldom used, we show in Section~\ref{s.L1} how to use it as a perturbation in the MILP model without incurring any expansive binary variables (only cheap linear variables are necessary). 



\item Bounds obtained on the full input space are particularly pessimistic, as all inputs, including {\em Out of Distribution (OOD \cite{OOD})} inputs far away from the training dataset, need to be accounted for. 
%As a result, the runtime to obtain the bound is particularly long. 
	%Finally, when computing worst-case 
	%pairs (image, perturbation), improbable images are generated, hence these  are not meaningful. 
To address this, we consider model order reduction techniques from engineering science \cite{Paco}. Specifically, we use Principal Component Analysis (PCA) to represent faithfully common inputs from the dataset. OOD	inputs may be represented unfaithfully, which is reasonable as the DNN is unlikely to provide reasonable answer on such inputs anyway.
	%	focus on reduce the space to a linear input space. We choose the number of dimensions of the space to equal the accuracy of the DNN on the reduced space. 
	%(using a projection to the reduced space then the inverse projection to obtain a very similar image understandable by the DNN). 
For instance, using just $20$ out of 784 dimensions suffices to represent faithfully MNIST inputs, without losing accuracy for the DNN on the MNIST dataset.
	%On the MNIST benchmark, this means 20 linear dimensions to match the $97\%$ accuracy of the DNN we considered, instead of the 784 dimensions of the full image space. 
	%Using PCA, which is linear, makes it easy to specify perturbations on the actual image (where it is meaningful) rather than on the reduced space.

\item Experimentally, the {\em Diff MILP model} computes upper bounds
$\bar{\beta}^{\varepsilon}_{C,D}$ which reduces the gap to the lower bound compared with optimized version of the classical MILP encoding; namely reducing the number of binary variables (VHAGaR \cite{vhagar}); or adding linear constraints from the {\em diff variables} (ITNE \cite{ITNE}), see Table \ref{table.classical}.
The abstractions  "2b+1" and "1b" variant offer different trade-offs, 
reaching better bounds than the {\em Diff MILP} model when the instance is very complex, or when runtime is limited (Table \ref{table.L1}).  
Further, using PCA reduces the upper bound $\beta_{C,D}$ by $3$ to $20$ times.
Overall, using these different techniques ({\em Diff} MILP model, abstraction and PCA) enables the real-time certification of $\geq 70\%$ of fresh images for an $L1$-perturbation of $1,4,2$ over the MNIST, Fashion MNIST and CIFAR-10 datasets respectively, see Table \ref{table.cert}. The online process adds only 0.5ms of latency per image, and 2000 images/second can be treated per CPU core.
\end{enumerate}