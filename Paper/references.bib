% Encoding: UTF-8

@Article{prima,
  author     = {M\"{u}ller, Mark Niklas and Makarchuk, Gleb and Singh, Gagandeep and P\"{u}schel, Markus and Vechev, Martin},
  journal    = {Proc. ACM Program. Lang.},
  title      = {PRIMA: General and Precise Neural Network Certification via Scalable Convex Hull Approximations},
  year       = {2022},
  month      = {jan},
  number     = {POPL},
  volume     = {6},
  abstract   = {Formal verification of neural networks is critical for their safe adoption in real-world applications. However, designing a precise and scalable verifier which can handle different activation functions, realistic network architectures and relevant specifications remains an open and difficult challenge. In this paper, we take a major step forward in addressing this challenge and present a new verification framework, called PRIMA. PRIMA is both (i) general: it handles any non-linear activation function, and (ii) precise: it computes precise convex abstractions involving multiple neurons via novel convex hull approximation algorithms that leverage concepts from computational geometry. The algorithms have polynomial complexity, yield fewer constraints, and minimize precision loss. We evaluate the effectiveness of PRIMA on a variety of challenging tasks from prior work. Our results show that PRIMA is significantly more precise than the state-of-the-art, verifying robustness to input perturbations for up to 20\%, 30\%, and 34\% more images than existing work on ReLU-, Sigmoid-, and Tanh-based networks, respectively. Further, PRIMA enables, for the first time, the precise verification of a realistic neural network for autonomous driving within a few minutes.},
  address    = {New York, NY, USA},
  articleno  = {43},
  doi        = {10.1145/3498704},
  issue_date = {January 2022},
  keywords   = {Polyhedra, Robustness, Abstract Interpretation, Convexity},
  numpages   = {33},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3498704},
}

@InProceedings{crown,
  author    = {Wang, Shiqi and Zhang, Huan and Xu, Kaidi and Lin, Xue and Jana, Suman and Hsieh, Cho-Jui and Kolter, J. Zico},
  booktitle = {Advances in Neural Information Processing Systems},
  title     = {Beta-CROWN: Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification},
  year      = {2021},
  editor    = {M. Ranzato and A. Beygelzimer and Y. Dauphin and P.S. Liang and J. Wortman Vaughan},
  pages     = {29909--29921},
  publisher = {Curran Associates, Inc.},
  volume    = {34},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2021/file/fac7fead96dafceaf80c1daffeae82a4-Paper.pdf},
}

@Article{deeppoly,
  author     = {Singh, Gagandeep and Gehr, Timon and P\"{u}schel, Markus and Vechev, Martin},
  journal    = {Proc. ACM Program. Lang.},
  title      = {An Abstract Domain for Certifying Neural Networks},
  year       = {2019},
  month      = {jan},
  number     = {POPL},
  volume     = {3},
  abstract   = {We present a novel method for scalable and precise certification of deep neural networks. The key technical insight behind our approach is a new abstract domain which combines floating point polyhedra with intervals and is equipped with abstract transformers specifically tailored to the setting of neural networks. Concretely, we introduce new transformers for affine transforms, the rectified linear unit (ReLU), sigmoid, tanh, and maxpool functions. We implemented our method in a system called DeepPoly and evaluated it extensively on a range of datasets, neural architectures (including defended networks), and specifications. Our experimental results indicate that DeepPoly is more precise than prior work while scaling to large networks. We also show how to combine DeepPoly with a form of abstraction refinement based on trace partitioning. This enables us to prove, for the first time, the robustness of the network when the input image is subjected to complex perturbations such as rotations that employ linear interpolation.},
  address    = {New York, NY, USA},
  articleno  = {41},
  doi        = {10.1145/3290354},
  issue_date = {January 2019},
  keywords   = {Adversarial attacks, Deep Learning, Abstract Interpretation},
  numpages   = {30},
  publisher  = {Association for Computing Machinery},
  url        = {https://doi.org/10.1145/3290354},
}

@InProceedings{Reluplex,
  author    = {Katz, Guy and Barrett, Clark and Dill, David L. and Julian, Kyle and Kochenderfer, Mykel J.},
  booktitle = {Computer Aided Verification},
  title     = {Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks},
  year      = {2017},
  address   = {Cham},
  editor    = {Majumdar, Rupak and Kun{\v{c}}ak, Viktor},
  pages     = {97--117},
  publisher = {Springer International Publishing},
  abstract  = {Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can successfully prove properties of networks that are an order of magnitude larger than the largest networks verified using existing methods.},
  isbn      = {978-3-319-63387-9},
}

@InProceedings{MILP,
  author    = {Gagandeep Singh and Timon Gehr and Markus Püschel and Martin Vechev},
  booktitle = {International Conference on Learning Representations},
  title     = {Robustness Certification with Refinement},
  year      = {2019},
  url       = {https://openreview.net/forum?id=HJgeEh09KQ},
}

@Article{zhang2018efficient,
  author  = {Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and Daniel, Luca},
  journal = {Advances in neural information processing systems},
  title   = {Efficient neural network robustness certification with general activation functions},
  year    = {2018},
  volume  = {31},
}

@InProceedings{wong2018provable,
  author       = {Wong, Eric and Kolter, Zico},
  booktitle    = {International conference on machine learning},
  title        = {Provable defenses against adversarial examples via the convex outer adversarial polytope},
  year         = {2018},
  organization = {PMLR},
  pages        = {5286--5295},
}

@InProceedings{wang2018formal,
  author    = {Wang, Shiqi and Pei, Kexin and Whitehouse, Justin and Yang, Junfeng and Jana, Suman},
  booktitle = {27th USENIX Security Symposium (USENIX Security 18)},
  title     = {Formal security analysis of neural networks using symbolic intervals},
  year      = {2018},
  pages     = {1599--1614},
}

@Article{Szegedy2013,
  author  = {Szegedy, Christian and Zaremba, Wojciech and Sutskever, Ilya and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian and Fergus, Rob},
  journal = {arXiv preprint arXiv:1312.6199},
  title   = {Intriguing properties of neural networks},
  year    = {2013},
}

@InProceedings{anderson2019optimization,
  author    = {Anderson, Greg and Pailoor, Shankara and Dillig, Isil and Chaudhuri, Swarat},
  booktitle = {Proceedings of the 40th ACM SIGPLAN conference on programming language design and implementation},
  title     = {Optimization and abstraction: a synergistic approach for analyzing neural network robustness},
  year      = {2019},
  pages     = {731--744},
}

@Article{Bak2021,
  author  = {Bak, Stanley and Liu, Changliu and Johnson, Taylor},
  journal = {arXiv preprint arXiv:2109.00498},
  title   = {The second international verification of neural networks competition (vnn-comp 2021): Summary and results},
  year    = {2021},
}

@InProceedings{balunovic2020adversarial,
  author       = {Balunovi{\'c}, Mislav and Vechev, Martin},
  booktitle    = {8th International Conference on Learning Representations (ICLR 2020)(virtual)},
  title        = {Adversarial training and provable defenses: Bridging the gap},
  year         = {2020},
  organization = {International Conference on Learning Representations},
}

@InProceedings{botoeva2020efficient,
  author    = {Botoeva, Elena and Kouvaros, Panagiotis and Kronqvist, Jan and Lomuscio, Alessio and Misener, Ruth},
  booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
  title     = {Efficient verification of relu-based neural networks via dependency analysis},
  year      = {2020},
  number    = {04},
  pages     = {3291--3299},
  volume    = {34},
}

@InProceedings{bunel2020lagrangian,
  author       = {Bunel, Rudy and De Palma, Alessandro and Desmaison, Alban and Dvijotham, Krishnamurthy and Kohli, Pushmeet and Torr, Philip and Kumar, M Pawan},
  booktitle    = {Conference on Uncertainty in Artificial Intelligence},
  title        = {Lagrangian decomposition for neural network verification},
  year         = {2020},
  organization = {PMLR},
  pages        = {370--379},
}

@Article{bunel2020branch,
  author  = {Bunel, Rudy and Lu, Jingyue and Turkaslan, Ilker and Torr, Philip HS and Kohli, Pushmeet and Kumar, M Pawan},
  journal = {Journal of Machine Learning Research},
  title   = {Branch and bound for piecewise linear neural network verification},
  year    = {2020},
  number  = {42},
  pages   = {1--39},
  volume  = {21},
}

@Article{bunel2018unified,
  author  = {Bunel, Rudy R and Turkaslan, Ilker and Torr, Philip and Kohli, Pushmeet and Mudigonda, Pawan K},
  journal = {Advances in Neural Information Processing Systems},
  title   = {A unified view of piecewise linear neural network verification},
  year    = {2018},
  volume  = {31},
}

@Article{dathathri2020enabling,
  author  = {Dathathri, Sumanth and Dvijotham, Krishnamurthy and Kurakin, Alexey and Raghunathan, Aditi and Uesato, Jonathan and Bunel, Rudy R and Shankar, Shreya and Steinhardt, Jacob and Goodfellow, Ian and Liang, Percy S and others},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Enabling certification of verification-agnostic networks via memory-efficient semidefinite programming},
  year    = {2020},
  pages   = {5318--5331},
  volume  = {33},
}

@InProceedings{de2021scaling,
  author       = {De Palma, Alessandro and Behl, Harkirat S and Bunel, Rudy and Torr, Philip and Kumar, M Pawan},
  booktitle    = {Proceedings of the ICLR 2021 Conference},
  title        = {Scaling the convex barrier with active sets},
  year         = {2021},
  organization = {Open Review},
}

@Article{DePalma2021,
  author  = {De Palma, Alessandro and Bunel, Rudy and Desmaison, Alban and Dvijotham, Krishnamurthy and Kohli, Pushmeet and Torr, Philip HS and Kumar, M Pawan},
  journal = {arXiv preprint arXiv:2104.06718},
  title   = {Improved branch and bound for neural network verification via lagrangian decomposition},
  year    = {2021},
}

@InProceedings{dutta2018output,
  author       = {Dutta, Souradeep and Jha, Susmit and Sankaranarayanan, Sriram and Tiwari, Ashish},
  booktitle    = {NASA Formal Methods Symposium},
  title        = {Output range analysis for deep feedforward neural networks},
  year         = {2018},
  organization = {Springer},
  pages        = {121--138},
}

@InProceedings{dvijotham2018dual,
  author    = {Dvijotham, Krishnamurthy and Stanforth, Robert and Gowal, Sven and Mann, Timothy A and Kohli, Pushmeet},
  booktitle = {UAI},
  title     = {A Dual Approach to Scalable Verification of Deep Networks.},
  year      = {2018},
  number    = {2},
  pages     = {3},
  volume    = {1},
}

@InProceedings{dvijotham2020efficient,
  author       = {Dvijotham, Krishnamurthy Dj and Stanforth, Robert and Gowal, Sven and Qin, Chongli and De, Soham and Kohli, Pushmeet},
  booktitle    = {Uncertainty in artificial intelligence},
  title        = {Efficient neural network verification with exactness characterization},
  year         = {2020},
  organization = {PMLR},
  pages        = {497--507},
}

@InProceedings{ehlers2017formal,
  author       = {Ehlers, Ruediger},
  booktitle    = {Automated Technology for Verification and Analysis: 15th International Symposium, ATVA 2017, Pune, India, October 3--6, 2017, Proceedings 15},
  title        = {Formal verification of piece-wise linear feed-forward neural networks},
  year         = {2017},
  organization = {Springer},
  pages        = {269--286},
}

@Article{fazlyab2020safety,
  author    = {Fazlyab, Mahyar and Morari, Manfred and Pappas, George J},
  journal   = {IEEE Transactions on Automatic Control},
  title     = {Safety verification and robustness analysis of neural networks via quadratic constraints and semidefinite programming},
  year      = {2020},
  number    = {1},
  pages     = {1--15},
  volume    = {67},
  publisher = {IEEE},
}

@InProceedings{gehr2018ai2,
  author       = {Gehr, Timon and Mirman, Matthew and Drachsler-Cohen, Dana and Tsankov, Petar and Chaudhuri, Swarat and Vechev, Martin},
  booktitle    = {2018 IEEE symposium on security and privacy (SP)},
  title        = {Ai2: Safety and robustness certification of neural networks with abstract interpretation},
  year         = {2018},
  organization = {IEEE},
  pages        = {3--18},
}

@Article{gowal2018effectiveness,
  author  = {Gowal, Sven and Dvijotham, Krishnamurthy and Stanforth, Robert and Bunel, Rudy and Qin, Chongli and Uesato, Jonathan and Arandjelovic, Relja and Mann, Timothy and Kohli, Pushmeet},
  journal = {arXiv preprint arXiv:1810.12715},
  title   = {On the effectiveness of interval bound propagation for training verifiably robust models},
  year    = {2018},
}

@InProceedings{huang2017safety,
  author       = {Huang, Xiaowei and Kwiatkowska, Marta and Wang, Sen and Wu, Min},
  booktitle    = {Computer Aided Verification: 29th International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part I 30},
  title        = {Safety verification of deep neural networks},
  year         = {2017},
  organization = {Springer},
  pages        = {3--29},
}

@Article{kingma2014adam,
  author  = {Kingma, Diederik P and Ba, Jimmy},
  journal = {International Conferenceon Learning Representations (ICLR)},
  title   = {Adam: A method for stochastic optimization},
  year    = {2014},
}

@Article{Vnncomp2020,
  author = {C. Liu and T. Johnson},
  title  = {Vnn comp 2020},
  url    = {https://sites.google.com/view/vnn20/vnncomp},
}

@Article{lu2019neural,
  author  = {Lu, Jingyue and Kumar, M Pawan},
  journal = {arXiv preprint arXiv:1912.01329},
  title   = {Neural network branching for neural network verification},
  year    = {2019},
}

@Article{madry2017towards,
  author  = {Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal = {International Conference on Learning Representations(ICLR)},
  title   = {Towards deep learning models resistant to adversarial attacks},
  year    = {2018},
}

@InProceedings{mirman2018differentiable,
  author       = {Mirman, Matthew and Gehr, Timon and Vechev, Martin},
  booktitle    = {International Conference on Machine Learning},
  title        = {Differentiable abstract interpretation for provably robust neural networks},
  year         = {2018},
  organization = {PMLR},
  pages        = {3578--3586},
}

@Article{Precisemultineuronabstractionsforneuralnetworkcertification2021,
  author  = {M. N. Müller, G. Makarchuk, G. Singh, M. Püschel, and M. Vechev},
  journal = {arXiv preprint arXiv:2103.03638},
  title   = {Precise multi-neuronabstractions for neural network certification},
  year    = {2021},
}

@Article{pattanaik2017robust,
  author  = {Pattanaik, Anay and Tang, Zhenyi and Liu, Shuijing and Bommannan, Gautham and Chowdhary, Girish},
  journal = {arXiv preprint arXiv:1712.03632},
  title   = {Robust deep reinforcement learning with adversarial attacks},
  year    = {2017},
}

@Article{raghunathan2018semidefinite,
  author  = {Raghunathan, Aditi and Steinhardt, Jacob and Liang, Percy S},
  journal = {Advances in neural information processing systems},
  title   = {Semidefinite relaxations for certifying robustness to adversarial examples},
  year    = {2018},
  volume  = {31},
}

@Article{rubies2019fast,
  author  = {Rubies-Royo, Vicenc and Calandra, Roberto and Stipanovic, Dusan M and Tomlin, Claire},
  journal = {arXiv preprint arXiv:1902.07247},
  title   = {Fast neural network verification via shadow prices},
  year    = {2019},
}

@Article{salman2019convex,
  author  = {Salman, Hadi and Yang, Greg and Zhang, Huan and Hsieh, Cho-Jui and Zhang, Pengchuan},
  journal = {Advances in Neural Information Processing Systems},
  title   = {A convex relaxation barrier to tight robustness verification of neural networks},
  year    = {2019},
  volume  = {32},
}

@Article{shi2020robustness,
  author  = {Shi, Zhouxing and Zhang, Huan and Chang, Kai-Wei and Huang, Minlie and Hsieh, Cho-Jui},
  journal = {International Conference on Learning Representations (ICLR)},
  title   = {Robustness verification for transformers},
  year    = {2020},
}

@Article{shi2021fast,
  author  = {Shi, Zhouxing and Wang, Yihan and Zhang, Huan and Yi, Jinfeng and Hsieh, Cho-Jui},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Fast certified robust training with short warmup},
  year    = {2021},
  pages   = {18335--18349},
  volume  = {34},
}

@Article{singh2018fast,
  author  = {Singh, Gagandeep and Gehr, Timon and Mirman, Matthew and P{\"u}schel, Markus and Vechev, Martin},
  journal = {Advances in neural information processing systems},
  title   = {Fast and effective robustness certification},
  year    = {2018},
  volume  = {31},
}

@InProceedings{singh2018boosting,
  author    = {Singh, Gagandeep and Gehr, Timon and P{\"u}schel, Markus and Vechev, Martin},
  booktitle = {International conference on learning representations},
  title     = {Boosting robustness certification of neural networks},
  year      = {2018},
}

@Article{singh2019beyond,
  author  = {Singh, Gagandeep and Ganvir, Rupanshu and P{\"u}schel, Markus and Vechev, Martin},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Beyond the single neuron convex barrier for neural network certification},
  year    = {2019},
  volume  = {32},
}

@Article{tjandraatmadja2020convex,
  author  = {Tjandraatmadja, Christian and Anderson, Ross and Huchette, Joey and Ma, Will and Patel, Krunal Kishor and Vielma, Juan Pablo},
  journal = {Advances in Neural Information Processing Systems},
  title   = {The convex relaxation barrier, revisited: Tightened single-neuron relaxations for neural network verification},
  year    = {2020},
  pages   = {21675--21686},
  volume  = {33},
}

@Article{tjeng2017evaluating,
  author  = {Tjeng, Vincent and Xiao, Kai and Tedrake, Russ},
  journal = {arXiv preprint arXiv:1711.07356},
  title   = {Evaluating robustness of neural networks with mixed integer programming},
  year    = {2017},
}

@Article{wang2018efficient,
  author  = {Wang, Shiqi and Pei, Kexin and Whitehouse, Justin and Yang, Junfeng and Jana, Suman},
  journal = {Advances in neural information processing systems},
  title   = {Efficient formal safety analysis of neural networks},
  year    = {2018},
  volume  = {31},
}

@Article{wong2018scaling,
  author  = {Wong, Eric and Schmidt, Frank and Metzen, Jan Hendrik and Kolter, J Zico},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Scaling provable adversarial defenses},
  year    = {2018},
  volume  = {31},
}

@Article{xu2020automatic,
  author  = {Xu, Kaidi and Shi, Zhouxing and Zhang, Huan and Wang, Yihan and Chang, Kai-Wei and Huang, Minlie and Kailkhura, Bhavya and Lin, Xue and Hsieh, Cho-Jui},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Automatic perturbation analysis for scalable certified robustness and beyond},
  year    = {2020},
  pages   = {1129--1141},
  volume  = {33},
}

@Article{xu2020fast,
  author  = {Xu, Kaidi and Zhang, Huan and Wang, Shiqi and Wang, Yihan and Jana, Suman and Lin, Xue and Hsieh, Cho-Jui},
  journal = {arXiv preprint arXiv:2011.13824},
  title   = {Fast and complete: Enabling complete neural network verification with rapid and massively parallel incomplete verifiers},
  year    = {2020},
}

@Article{zhang2018efficient,
  author  = {Zhang, Huan and Weng, Tsui-Wei and Chen, Pin-Yu and Hsieh, Cho-Jui and Daniel, Luca},
  journal = {Advances in neural information processing systems},
  title   = {Efficient neural network robustness certification with general activation functions},
  year    = {2018},
  volume  = {31},
}

@Article{zhang2019towards,
  author  = {Zhang, Huan and Chen, Hongge and Xiao, Chaowei and Gowal, Sven and Stanforth, Robert and Li, Bo and Boning, Duane and Hsieh, Cho-Jui},
  journal = {arXiv preprint arXiv:1906.06316},
  title   = {Towards stable and efficient training of verifiably robust neural networks},
  year    = {2019},
}

@Article{zhang2020robust,
  author  = {Zhang, Huan and Chen, Hongge and Xiao, Chaowei and Li, Bo and Liu, Mingyan and Boning, Duane and Hsieh, Cho-Jui},
  journal = {Advances in Neural Information Processing Systems},
  title   = {Robust deep reinforcement learning against adversarial perturbations on state observations},
  year    = {2020},
  pages   = {21024--21037},
  volume  = {33},
}

@Article{zhang2021robust,
  author  = {Zhang, Huan and Chen, Hongge and Boning, Duane and Hsieh, Cho-Jui},
  journal = {arXiv preprint arXiv:2101.08452},
  title   = {Robust reinforcement learning on state observations with learned optimal adversary},
  year    = {2021},
}

@Article{anderson2020strong,
  author    = {Anderson, Ross and Huchette, Joey and Ma, Will and Tjandraatmadja, Christian and Vielma, Juan Pablo},
  journal   = {Mathematical Programming},
  title     = {Strong mixed-integer programming formulations for trained neural networks},
  year      = {2020},
  number    = {1-2},
  pages     = {3--39},
  volume    = {183},
  publisher = {Springer},
}

@Article{avis1991basis,
  author    = {Avis, David and Fukuda, Komei},
  journal   = {Applied Mathematics Letters},
  title     = {A basis enumeration algorithm for linear systems with geometric applications},
  year      = {1991},
  number    = {5},
  pages     = {39--42},
  volume    = {4},
  publisher = {Elsevier},
}

@InProceedings{avis1991pivoting,
  author    = {Avis, David and Fukuda, Komei},
  booktitle = {Proceedings of the seventh annual symposium on Computational geometry},
  title     = {A pivoting algorithm for convex hulls and vertex enumeration of arrangements and polyhedra},
  year      = {1991},
  pages     = {98--104},
}

@Comment{jabref-meta: databaseType:bibtex;}
